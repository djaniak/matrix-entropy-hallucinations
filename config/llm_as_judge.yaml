defaults:
  - prompt: ???
  - _self_

llm_name: llama3.1
answer_column_name: prediction
answers_file: ???
